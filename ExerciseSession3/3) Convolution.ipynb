{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1JnLtxizvfy5rT4KByB9_doIb4U1n2eeo","timestamp":1634807240856}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ENYgUuszSiGl"},"source":["### Connect to Drive"]},{"cell_type":"code","metadata":{"id":"MEXdF8O1cBA7"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W6R4A_0FcJXG"},"source":["%cd /gdrive/My Drive/2022_AN2DL(Private)/ExerciseSession3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZRUUeiHySj4K"},"source":["### Import libraries"]},{"cell_type":"code","metadata":{"id":"7xoHwf0ZfRNu"},"source":["import os\n","import time \n","\n","import random\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import tensorflow as tf\n","import numpy as np\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","print(tf.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IdmOtoZNfWMD"},"source":["# Random seed for reproducibility\n","seed = 42\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TCaGhb5ttXGc"},"source":["### Load data "]},{"cell_type":"code","metadata":{"id":"9DUtctbDJXBi"},"source":["# Import the image as single channel\n","image = Image.open('picture.jpg').convert('L')\n","print(\"Original image shape: \", image.size)\n","image = image.resize((512,512))\n","print(\"Resized image shape: \", image.size)\n","fig = plt.figure(figsize=(8, 8))\n","plt.imshow(image, cmap='gray')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_i87JVq4JyC-"},"source":["# Convert the image into an array\n","image = np.array(image, dtype=np.float32)\n","image_h, image_w = image.shape[:2]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cd7YL7bN74Qx"},"source":["### 2D Convolution\n","\n","$\n","\\begin{align}\n","\\sum_{s=-a}^{s=a}\\sum_{t=-b}^{t=b}{w(s, t) f(x-s, y-t)}\n","\\end{align}\n","$\n","\n","![](https://drive.google.com/uc?export=view&id=1lr0M3W6LEedxZLXaCxt0JGjhmEjkHoq5\n",")\n","\n","Implemented in Keras as cross-correlation!\n","\n","$\n","\\begin{align}\n","\\sum_{s=-a}^{s=a}\\sum_{t=-b}^{t=b}{w(s, t) f(x+s, y+t)}\n","\\end{align}\n","$"]},{"cell_type":"markdown","metadata":{"id":"dtV6nWX6SsgR"},"source":["### Example: Edge Detection\n","\n","## Sobel Filter\n","\n","##### - $w_h$: horizontal sobel filter\n","##### - $w_v$: vertical sobel filter\n","\n","![](https://drive.google.com/uc?export=view&id=1jpP6QP4IzChc0eOw7UudQStKYWgZw6yn\n",")\n","\n","Edges magnitude\n","\n","$\n","\\begin{align}\n","e(x,y) = \\sqrt{e_h(x,y)^2 + e_v(x,y)^2}\n","\\end{align}\n","$"]},{"cell_type":"code","metadata":{"id":"usDsvuGonnsx"},"source":["# Function to plot image and filters\n","def plot_edges(orig_image, h_edge_image, v_edge_image, edge_image):\n","  print(\"Original image shape:\", orig_image.shape)\n","  print(\"Horizontal edge image shape:\", h_edge_image.shape)\n","  print(\"Vertical edge image shape:\", v_edge_image.shape)\n","  print(\"Edge image shape:\", edge_image.shape)\n","  fig, ax = plt.subplots(1, 4, figsize=(15, 45))\n","  ax[0].imshow(orig_image, cmap='gray')\n","  ax[1].imshow(h_edge_image, cmap='gray')\n","  ax[2].imshow(v_edge_image, cmap='gray')\n","  ax[3].imshow(edge_image, cmap='gray')\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MwaqdwGlcpbj"},"source":["# Define Sobel filters\n","# Horizontal filter\n","def kernel_h_init(shape, dtype=None, partition_info=None):\n","    kernel = tf.constant([[1,0,-1],\n","                          [2,0,-2],\n","                          [1,0,-1]], dtype=dtype)\n","    kernel = tf.reshape(kernel, shape)\n","\n","    return kernel\n","# Vertical filter\n","def kernel_v_init(shape, dtype=None, partition_info=None):\n","    kernel = tf.constant([[1,2,1],\n","                          [0,0,0],\n","                          [-1,-2,-1]], dtype=dtype)\n","    kernel = tf.reshape(kernel, shape)\n","\n","    return kernel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7-kKf3LStpyg"},"source":["# Compute the edges by (manually) convolving the input with the filters\n","stride = 1\n","kernel_size = 3\n","\n","h_kernel = kernel_h_init(shape=[3, 3], dtype=None)\n","v_kernel = kernel_v_init(shape=[3, 3], dtype=None)\n","\n","h_edges = np.zeros([image_h, image_w])\n","v_edges = np.zeros([image_h, image_w])  \n","edges = np.zeros([image_h, image_w])\n","\n","# Slide the filters over the image\n","for i in np.arange(0, image_h-kernel_size+1, stride):\n","    for j in np.arange(0, image_w-kernel_size+1, stride):\n","        # Apply the filter\n","        h_out = image[i:i+kernel_size,j:j+kernel_size] * h_kernel[:, :]\n","        h_out = tf.reduce_sum(h_out)\n","        v_out = image[i:i+kernel_size,j:j+kernel_size] * v_kernel[:, :]\n","        v_out = tf.reduce_sum(v_out)\n","\n","        h_edges[i, j] = h_out\n","        v_edges[i, j] = v_out\n","        edges[i, j] = np.sqrt(h_out**2+v_out**2)\n","\n","h_edges = h_edges[:image_h-kernel_size+1, :image_w-kernel_size+1]\n","v_edges = v_edges[:image_h-kernel_size+1, :image_w-kernel_size+1]\n","edges = edges[:image_h-kernel_size+1, :image_w-kernel_size+1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XOtqo79yJ9KD"},"source":["plot_edges(image, h_edges, v_edges, edges)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lEg_Qd1pzg3D"},"source":["# 2D Convolutial Layer - tfk.layers.Conv2D\n","\n","### Number of filters\n","\n","![](https://drive.google.com/uc?export=view&id=1SggjDYVceiT04SM-Aza8eRzhkNZ9i3vs\n",")\n","\n","\n","### Filter size\n","\n","![](https://drive.google.com/uc?export=view&id=1To2GJs-HDPbKZSRwu592V1CyQ4U5QY96\n",")\n","\n","### Stride\n","\n","![](https://drive.google.com/uc?export=view&id=1dacOoU5nBg_mSyd7K6E5F9uY_e3haIru\n",")"]},{"cell_type":"code","metadata":{"id":"3H88izA6tpGE"},"source":["# Create Conv2D layer\n","conv2d_h = tfkl.Conv2D(1, [kernel_size, kernel_size], strides=(stride, stride), \n","                       kernel_initializer=kernel_h_init, input_shape=(image_h,image_w,1))\n","\n","conv2d_v = tfkl.Conv2D(1, [kernel_size, kernel_size], strides=(stride, stride),\n","                       kernel_initializer=kernel_v_init, input_shape=(image_h,image_w,1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2NU_k5EQk57g"},"source":["h_edges_conv = conv2d_h(image[None, :, :, None]) # 'None' to add batch and channel dimensions\n","v_edges_conv = conv2d_v(image[None, :, :, None]) # 'None' to add batch and channel dimensions\n","\n","h_edges_conv = h_edges_conv[0, :, :, 0]\n","v_edges_conv = v_edges_conv[0, :, :, 0]\n","edges_conv = np.sqrt(h_edges_conv**2+v_edges_conv**2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Y1rUZDP0uU0"},"source":["# Check the result of the \"manual\" convolution and \n","# the result of the Keras convolution are the same \n","assert np.allclose(h_edges, h_edges_conv)\n","print(\"OK. Horizontal edges are the same!\")\n","assert np.allclose(v_edges, v_edges_conv)\n","print(\"OK. Vertical edges are the same!\")\n","assert np.allclose(edges, edges_conv)\n","print(\"OK. Edge magnutides are the same!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Co2ap7PtlBGC"},"source":["plot_edges(image, h_edges_conv, v_edges_conv, edges_conv)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K-lN3Rke2CWB"},"source":["### Padding"]},{"cell_type":"code","metadata":{"id":"2L31TCbO2FRs"},"source":["# What about input and Conv2D output shapes?\n","print(\"Original image shape:\", image.shape)\n","print(\"Conv2D output shape:\", h_edges_conv.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0F3H19c5WSeZ"},"source":["Convolutions reduce the spatial dimension!\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1kHpyc_-HRVM3J_8jqBTEYtIUAbWe4Ijv\" width=\"256\"/>\n","\n","We need to add padding\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1eEZhWEg_uuf44B14b0vUQZFmlpj36rm_\" width=\"256\"/>\n","\n","$\\tiny Images\\ source:$ \n","https://github.com/vdumoulin/conv_arithmetic\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Z6X5jtMlWOtP"},"source":["# Create Conv2D layer with padding\n","conv2d_pad_h = tfkl.Conv2D(1, [kernel_size, kernel_size], strides=(stride, stride),\n","                           kernel_initializer=kernel_h_init, input_shape=(image_h,image_w,1), padding='same')\n","\n","# Create Conv2D layer with padding\n","conv2d_pad_v = tfkl.Conv2D(1, [kernel_size, kernel_size], strides=(stride, stride),\n","                           kernel_initializer=kernel_v_init, input_shape=(image_h,image_w,1), padding='same')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UeQCEWTQcuSw"},"source":["h_edges_conv_pad = conv2d_pad_h(image[None, :, :, None])\n","v_edges_conv_pad = conv2d_pad_v(image[None, :, :, None])\n","\n","h_edges_conv_pad = h_edges_conv_pad[0, :, :, 0]\n","v_edges_conv_pad = v_edges_conv_pad[0, :, :, 0]\n","edges_conv_pad = np.sqrt(h_edges_conv_pad**2+v_edges_conv_pad**2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DD2ZXPEqfQSA"},"source":["# What about the shapes now?\n","print(\"Original image shape:\", image.shape)\n","print(\"Conv2D output shape:\", h_edges_conv_pad.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDCKYKCfepI8"},"source":["# If we remove the padding in the output, we obtain\n","# the same result of the convolution with no padding\n","assert np.allclose(h_edges_conv, h_edges_conv_pad[1:511, 1:511])\n","print(\"OK. Horizontal edges are the same!\")\n","assert np.allclose(v_edges_conv, v_edges_conv_pad[1:511, 1:511])\n","print(\"OK. Vertical edges are the same!\")\n","assert np.allclose(edges_conv, edges_conv_pad[1:511, 1:511])\n","print(\"OK. Edge magnutides are the same!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fDvuAA1cfUPC"},"source":["# Learning the Conv2D filter\n","\n","Suppose that the Sobel filter is unknown. Let's learn it!\n"]},{"cell_type":"code","metadata":{"id":"1HR5K3tW5a2I"},"source":["# Horizontal edge model\n","h_edge_model = tfk.Sequential()\n","h_edge_model.add(tfkl.Conv2D(1, [kernel_size, kernel_size], strides=(stride, stride), \n","                 kernel_initializer=tfk.initializers.GlorotUniform(seed=seed),\n","                 input_shape=(image_h,image_w,1), padding='valid'))\n","\n","h_edge_model.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(learning_rate=1e-1))\n","\n","# Vertical edge model\n","v_edge_model = tfk.Sequential()\n","v_edge_model.add(tfkl.Conv2D(1, [kernel_size, kernel_size], strides=(stride, stride), \n","                 kernel_initializer=tfk.initializers.GlorotUniform(seed=seed),\n","                 input_shape=(image_h,image_w,1), padding='valid'))\n","\n","v_edge_model.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(learning_rate=1e-1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"elP-_CHcLkgs"},"source":["# Horizontal edge model training\n","h_edge_model.fit(\n","    x=image[None, ..., None], \n","    y=h_edges[None, ..., None], \n","    epochs=3000, batch_size=1,\n","    callbacks=[tfk.callbacks.EarlyStopping(monitor='loss', mode='min', patience=100, restore_best_weights=True)])\n","\n","# Vertical edge model training\n","v_edge_model.fit(\n","    x=image[None, ..., None], \n","    y=v_edges[None, ..., None], \n","    epochs=3000, batch_size=1,\n","    callbacks=[tfk.callbacks.EarlyStopping(monitor='loss', mode='min', patience=100, restore_best_weights=True)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9XXae_rQkic"},"source":["# Compare the learned filter with the Sobel one\n","learned_h_kernel = h_edge_model.weights[0].numpy()\n","learned_v_kernel = v_edge_model.weights[0].numpy()\n","\n","print(\"Learned horizontal edge filter\")\n","print()\n","print(learned_h_kernel[..., 0, 0].round(1))\n","print()\n","print(\"Learned vertical edge filter\")\n","print()\n","print(learned_v_kernel[..., 0, 0].round(1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMYBjK_Mszuy"},"source":["# Check if learned and original Sobel filters are the same\n","assert np.allclose(h_kernel, learned_h_kernel[..., 0, 0].round(1))\n","assert np.allclose(v_kernel, learned_v_kernel[..., 0, 0].round(1))\n","print(\"OK. Learned and original Sobel filters are the same!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JaJuL4wEFkcm"},"source":["Surprise?\n","\n","x = Wy + b, where x = {image}, y = {edge}\n","\n","We have simply applied gradient descent to solve a linear equation"]},{"cell_type":"markdown","metadata":{"id":"aK4w4rio6Tx4"},"source":["# Convolutional Neural Network (CNN)\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1olry2CytupQhyiUPDgFR5gtH3lslbmJF\" width=\"600\"/>\n","\n","## Architecture \n","### Conv + Activation (+ Conv + Activation)$^+$ + Pooling + Fully-connected\n","\n","# 2D Pooling\n","\n","2D Average Pooling\n","\n","* Reduces the spatial dimensions of features\n","* Reduces the number of parameters, then the complexity of the network\n","* Provides local translation invariance\n","\n"]},{"cell_type":"code","metadata":{"id":"Iq7ytO7G6XEm"},"source":["# Create example tensor 4x4\n","tensor = tf.reshape(tf.range(0, 4*4, dtype=tf.float32), [1, 4, 4, 1])\n","print(\"Tensor shape:\", tensor.shape)\n","print(\"Tensor values:\")\n","print(tensor[0, ..., 0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZCIzyqdvCdYy"},"source":["# 2D Average Pooling\n","avg_pool2d = tfkl.AvgPool2D()\n","out = avg_pool2d(tensor)\n","print(\"Output shape:\", out.shape)\n","print(\"Output values:\")\n","print(out[0, ..., 0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XEGEFt7QCe2h"},"source":["# 2D Max Pooling\n","max_pool2d = tfkl.MaxPool2D()\n","out = max_pool2d(tensor)\n","print(\"Output shape:\", out.shape)\n","print(\"Output values:\")\n","print(out[0, ..., 0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G-pGa26zD0dc"},"source":["# Global Average Pooling\n","global_avg_pool2d = tfkl.GlobalAvgPool2D()\n","out = global_avg_pool2d(tensor)\n","print(\"Output shape:\", out.shape)\n","print(\"Output values:\")\n","print(out[0, ..., 0])"],"execution_count":null,"outputs":[]}]}