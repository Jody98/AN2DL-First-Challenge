{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1tr9_76ivIJEvByIYRFSmbigkWdwxh_o3","timestamp":1668965714339}],"collapsed_sections":["NXfTsE3-ezCA","Zk3Be29ul_f4","smsRsHKQTNRi","3s5JyXu6BDEc"],"authorship_tag":"ABX9TyOUI6emr+BrvstHQH7bFVd8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["This notebook contains to experiment with transfer leanring + custom classifier/GAP-softmax. With the possibility to apply fine tuning and to freeze portion of the network. All the experiments we have run can be implemented by modifying the configuraion object in the \"Experiment environment\" section"],"metadata":{"id":"6PdGqx-AErgp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"px7rhYi7efmD"},"outputs":[],"source":["import tensorflow as tf\n","import random\n","import numpy as np\n","import os\n","import tempfile\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import tensorflow_datasets as tfds\n","import datetime\n","import pickle\n","import time\n","from keras.utils.layer_utils import count_params\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization, Rescaling, RandomFlip, RandomRotation, RandomZoom, RandomTranslation, RandomContrast, Rescaling, AveragePooling2D\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers"]},{"cell_type":"markdown","source":["# Data import "],"metadata":{"id":"NXfTsE3-ezCA"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2802,"status":"ok","timestamp":1669206831606,"user":{"displayName":"Gianmario C","userId":"01154362426832162044"},"user_tz":-60},"id":"JsCXZL76rUPk","outputId":"b0924889-1c89-4e8c-958b-c79c262886c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsR2QzqkN280"},"outputs":[],"source":["# Random seed for reproducibility\n","seed = 44\n","\n","random.seed(seed)\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","tf.compat.v1.set_random_seed(seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34LvQl5sSdP3"},"outputs":[],"source":["# Dataset folders \n","dataset_dir = '../gdrive/MyDrive/ann_dataset'\n","dataset_folder = os.path.join(dataset_dir, 'ann_dataset')\n","\n","test_folder = os.path.join(dataset_dir, 'test')\n","train_folder = os.path.join(dataset_dir, 'train')"]},{"cell_type":"code","source":["IMG_SHAPE = (96,96, 3)"],"metadata":{"id":"sA1yhobFledq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_weight = {}\n","\n","for i in range(8):\n","  class_weight[i] = 1.5 if i != 0 else 1\n","\n","class_weight"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I_kejrYe-f-p","executionInfo":{"status":"ok","timestamp":1669211700908,"user_tz":-60,"elapsed":792,"user":{"displayName":"Gianmario C","userId":"01154362426832162044"}},"outputId":"21166928-caa5-482c-e678-fa586edde154"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 1, 1: 1.5, 2: 1.5, 3: 1.5, 4: 1.5, 5: 1.5, 6: 1.5, 7: 1.5}"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["# Functions"],"metadata":{"id":"Zk3Be29ul_f4"}},{"cell_type":"code","source":["# count trainble not trainable parameters given a keras model\n","def count_w(model, context=\"\"):\n","  trainable_count = count_params(model.trainable_weights)\n","  non_trainable_count = count_params(model.non_trainable_weights)\n","  print(f\"\\n{context}\\nTrainable: \\t\\t{trainable_count}\\nNon Trainable:  \\t{non_trainable_count}\")"],"metadata":{"id":"9iNMoZ5xlm1S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function to add regularization on the pretrained part of the network\n","def add_regularization(model, regularizer):\n","\n","    if not isinstance(regularizer, tf.keras.regularizers.Regularizer):\n","      raise Exception(\"Regularizer must be a subclass of tf.keras.regularizers.Regularizer\")\n","\n","    for layer in model.layers:\n","        for attr in ['kernel_regularizer']:\n","            if hasattr(layer, attr):\n","              setattr(layer, attr, regularizer)\n","\n","    # When we change the layers attributes, the change only happens in the model config file\n","    model_json = model.to_json()\n","\n","    # Save the weights before reloading the model.\n","    tmp_weights_path = os.path.join(tempfile.gettempdir(), 'tmp_weights.h5')\n","    model.save_weights(tmp_weights_path)\n","\n","    # load the model from the config\n","    model = tf.keras.models.model_from_json(model_json)\n","    \n","    # Reload the model weights\n","    model.load_weights(tmp_weights_path, by_name=True)\n","    return model"],"metadata":{"id":"Ztw1xcMuccnm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# wrapper function that return a model composed by  pretrained model + GAP softmax\n","def bottom_model_builder_fully_conv(\n","    base_model,\n","    dropout_rate,\n","    data_augmentation_layer,\n","    preprocessing_layer = None,\n","    preprocessing=False,\n","    data_aug = False\n","    ):\n","\n","  inputs=tfk.Input(shape=IMG_SHAPE)\n","  x = inputs\n","  if data_aug:\n","    x = data_augmentation_layer(x)\n","\n","  if preprocessing:\n","     x = preprocessing_layer(x)\n","  x = base_model(x)\n","  x = tfkl.GlobalAveragePooling2D()(x)\n","  x = Dropout(dropout_rate, name=\"top_dropout\")(x)\n","  outputs = tfkl.Dense(\n","      8, \n","      activation='softmax',\n","      kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n","\n","\n","  # Connect input and output through the Model class\n","  tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","\n","  return tl_model"],"metadata":{"id":"229Z8AcaSlwN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# wrapper function that return a model composed by  pretrained model + custom FFNN as classifier at the end\n","def bottom_model_builder_classifier(\n","    base_model,\n","    dropout_rate,\n","    data_augmentation_layer,\n","    preprocessing_layer = None,\n","    preprocessing=False,\n","    data_aug = False,\n","    size_dense =10000\n","    ):\n","\n","  inputs=tfk.Input(shape=IMG_SHAPE)\n","  x = inputs\n","  if data_aug:\n","    x = data_augmentation_layer(x)\n","\n","  if preprocessing:\n","     x = preprocessing_layer(x)\n","  x = base_model(x)\n","  x = tfkl.GlobalAveragePooling2D()(x)\n","  #x = Dropout(dropout_rate, name=\"top_dropout_1\")(x)\n","  x = Dense(size_dense, activation='swish')(x)\n","  x = Dropout(dropout_rate, name=\"top_dropout_2\")(x)\n","  x = Dense(256, activation='swish')(x)\n","  x = Dropout(dropout_rate, name=\"top_dropout_3\")(x)\n","  outputs = tfkl.Dense(\n","      8, \n","      activation='softmax',\n","      kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n","\n","\n","  # Connect input and output through the Model class\n","  tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n","\n","  return tl_model"],"metadata":{"id":"S296A9ovl6Oz","colab":{"base_uri":"https://localhost:8080/","height":162},"executionInfo":{"status":"ok","timestamp":1669206831654,"user_tz":-60,"elapsed":82,"user":{"displayName":"Gianmario C","userId":"01154362426832162044"}},"outputId":"947fb800-3113-4767-814f-f06eea1da9ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'def bottom_model_builder_classifier(\\n    base_model,\\n    dropout_rate,\\n    data_augmentation_layer,\\n    preprocessing_layer = None,\\n    preprocessing=False,\\n    data_aug = False,\\n    size_dense =10000\\n    ):\\n\\n  inputs=tfk.Input(shape=IMG_SHAPE)\\n  x = inputs\\n  if data_aug:\\n    x = data_augmentation_layer(x)\\n\\n  if preprocessing:\\n     x = preprocessing_layer(x)\\n  x = base_model(x)\\n  x = tfkl.GlobalAveragePooling2D()(x)\\n  #x = Dropout(dropout_rate, name=\"top_dropout_1\")(x)\\n  x = Dense(size_dense, activation=\\'swish\\')(x)\\n  x = Dropout(dropout_rate, name=\"top_dropout_2\")(x)\\n  x = Dense(256, activation=\\'swish\\')(x)\\n  x = Dropout(dropout_rate, name=\"top_dropout_3\")(x)\\n  outputs = tfkl.Dense(\\n      8, \\n      activation=\\'softmax\\',\\n      kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\\n\\n\\n  # Connect input and output through the Model class\\n  tl_model = tfk.Model(inputs=inputs, outputs=outputs, name=\\'model\\')\\n\\n  return tl_model'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# function containing all the logic for training a model given the setup data as parameter\n","def run_experiment(\n","    PATIENCE, \n","    EPOCHS, \n","    EXPERIMENT_NAME, \n","    SELECTED_MODEL,\n","    DROPOUT,\n","    USE_DATA_AUG,\n","    FREEZE_PERCENT,\n","    REGULARIZER,\n","    BATCH_SIZE,\n","    PREPROCESSING,\n","    SAVE_ACCURACY,\n","    PRE_TRAIN_CLASSIFIER,\n","    AUG_LAYER,\n","    L_RATE_FINETUNING,\n","    DROPOUT_RATE_CLASSIFIER):\n","  \n","  # not parameters to set\n","  USE_REG = REGULARIZER is not None\n","  USE_PREPROCESSING = PREPROCESSING is not None\n","  history_pretraining ={}\n","\n","  # data aumentation function default\n","  data_augmentation_layer = AUG_LAYER\n","  \n","  # callback list\n","  callbacks_list = []\n","  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=PATIENCE, restore_best_weights=True)\n","  callbacks_list.append(es_callback)\n","\n","  # metrics\n","  metrics = [\n","    tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n","  ]\n","\n","\n","  # build train and validation dataset and activate prefetching \n","  train_dataset = tfk.utils.image_dataset_from_directory(\n","      directory=train_folder,\n","      labels=\"inferred\",\n","      label_mode=\"categorical\",\n","      color_mode='rgb',\n","      image_size=(96,96),\n","      batch_size=BATCH_SIZE\n","  )\n","  validation_dataset = tfk.utils.image_dataset_from_directory(\n","      directory=test_folder,\n","      labels=\"inferred\",\n","      label_mode=\"categorical\",\n","      color_mode='rgb',\n","      image_size=(96,96),\n","  )\n","  AUTOTUNE = tf.data.AUTOTUNE\n","  train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n","  validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n","\n","  # create base model\n","  base_model = SELECTED_MODEL(input_shape=IMG_SHAPE,\n","                              include_top=False,\n","                              weights='imagenet',\n","                              drop_connect_rate=DROPOUT)\n","  \n","  if PRE_TRAIN_CLASSIFIER:\n","    print(\"\\nPre training activated\")\n","    # freeze the imported feature extractor and train only classifier\n","    base_model.trainable = False\n","    trainable_count = count_params(base_model.trainable_weights)\n","    non_trainable_count = count_params(base_model.non_trainable_weights)\n","    print(f\"\\nBase model before Pretraining\\nTrainable: \\t\\t{trainable_count}\\nNon Trainable:  \\t{non_trainable_count}\")\n","\n","    if trainable_count != 0:\n","      raise Exception('Trainable parameter are not zero! During pretraining the base model should be completely freezed')\n","\n","    model = bottom_model_builder_fully_conv(\n","      base_model = base_model,\n","      data_augmentation_layer = data_augmentation_layer,\n","      preprocessing_layer=PREPROCESSING,\n","      data_aug=USE_DATA_AUG,\n","      preprocessing=USE_PREPROCESSING,\n","      dropout_rate=DROPOUT_RATE_CLASSIFIER\n","      )\n","    \n","    # Compile model\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(), \n","        loss=tfk.losses.CategoricalCrossentropy(), \n","        metrics=metrics\n","        )\n","    \n","    # train only classifier (forced low patience)\n","    history_pretraining = model.fit(\n","      train_dataset,\n","      epochs = EPOCHS,\n","      validation_data = validation_dataset,\n","      callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)],\n","      class_weight=class_weight\n","      ).history\n","\n","    print(f\"\\nPretrain ended with val accuracy: {np.max(history_pretraining['val_accuracy'])}\")\n","\n","    # restore base model to trainable\n","    base_model.trainable = True\n","    # set everything trainable in the model\n","    model.trainable = True\n","\n","  trainable_count = count_params(base_model.trainable_weights)\n","  non_trainable_count = count_params(base_model.non_trainable_weights)\n","  print(f\"\\nBefore Freeze\\nTrainable: \\t\\t{trainable_count}\\nNon Trainable:  \\t{non_trainable_count}\")\n","\n","  # select percentage to freeze\n","  len_network = len(base_model.layers)\n","  freeze_n = int(len_network * FREEZE_PERCENT)\n","  print(f\"\\nnetwrok size {len_network} freezed layers -> {freeze_n}\")\n","\n","  # freeze top n layers\n","  for layer in base_model.layers[:freeze_n]:\n","      layer.trainable = False\n","\n","  # force all batch normalization to be non trainable\n","  for layer in base_model.layers:\n","    if isinstance(layer, tfkl.BatchNormalization):\n","      layer.trainable = False\n","\n","  trainable_count = count_params(base_model.trainable_weights)\n","  non_trainable_count = count_params(base_model.non_trainable_weights)\n","  print(f\"\\nAfter Freeze\\nTrainable: \\t\\t{trainable_count}\\nNon Trainable:  \\t{non_trainable_count}\")\n","\n","\n","  if not PRE_TRAIN_CLASSIFIER:\n","    # if there is no pretrain create the model here and compile with standard learning rate\n","    model = bottom_model_builder_fully_conv(\n","        base_model = base_model,\n","        data_augmentation_layer = data_augmentation_layer,\n","        preprocessing_layer=PREPROCESSING,\n","        data_aug=USE_DATA_AUG,\n","        preprocessing=USE_PREPROCESSING,\n","        dropout_rate=DROPOUT_RATE_CLASSIFIER\n","        )\n","    \n","    # add regulariazation\n","    if USE_REG:\n","      model = add_regularization(model, regularizer=REGULARIZER)\n","    \n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(), \n","        loss=tfk.losses.CategoricalCrossentropy(), \n","        metrics=metrics\n","        )\n","\n","  else:\n","    count_w(model, \"Compiled model for fine tuning\")\n","\n","    # add regulariazation\n","    if USE_REG:\n","      model = add_regularization(model, regularizer=REGULARIZER)\n","\n","    # compile again with lower learnign rate\n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(L_RATE_FINETUNING), \n","        loss=tfk.losses.CategoricalCrossentropy(), \n","        metrics=metrics\n","        )\n","\n","  # start training\n","  history = model.fit(\n","      train_dataset,\n","      epochs = EPOCHS,\n","      validation_data = validation_dataset,\n","      callbacks = callbacks_list,\n","      class_weight=class_weight\n","      ).history\n","  \n","\n","  if np.max(history['val_accuracy']) > SAVE_ACCURACY:\n","    print(f\"\\n ** GOOD MODEL FOUND **\")\n","    model_name = f\"Model_{EXPERIMENT_NAME}{int(time.time())}{np.max(history['val_accuracy']):.4}\"\n","    model.save(model_name)\n","\n","  return history, history_pretraining"],"metadata":{"id":"VWWAo8xrhxqa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Experiment environment"],"metadata":{"id":"smsRsHKQTNRi"}},{"cell_type":"code","source":["# ********************* SETUP OF THE LOOP *************************\n","fixed_params = {\n","  'EXPERIMENT_NAME' : \"name\",\n","  'SELECTED_MODEL' : tfk.applications.EfficientNetB4,\n","  'SAVE_ACCURACY': 0.88,\n","  'PATIENCE' : 25,\n","  'EPOCHS' : 500,\n","  'PRE_TRAIN_CLASSIFIER': True,\n","  'USE_DATA_AUG' : True,\n","  'BATCH_SIZE' : 64,\n","  'PREPROCESSING' : None, # example -> tf.keras.applications.mobilenet_v2.preprocess_input\n","  'FREEZE_PERCENT':0.05,\n","  'L_RATE_FINETUNING' : 1e-5,\n","  'AUG_LAYER' : Sequential([\n","                  tf.keras.layers.RandomFlip(),\n","                  tf.keras.layers.RandomRotation(0.3),\n","                  ]),\n","  'REGULARIZER' : tfk.regularizers.L2(0.05)\n","}\n","\n","# They list must have same size\n","params_grid = {\n","    'DROPOUT_RATE_CLASSIFIER': [0.3],\n","    'DROPOUT':[0.2],\n","  }\n","\n","# ************** END SETUP ****************\n","l = 0\n","for _, value in params_grid.items():\n","  if l == 0:\n","    l = len(value)\n","  if l != len(value):\n","    raise Exception(\"Param grid bad format all lenghts should be the same\")"],"metadata":{"id":"8_u3_olvJ3cO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history_name =  f\"history_list{int(time.time())}.p\""],"metadata":{"id":"yy-FPWN3nXQJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# run loop\n","history_metadata = []\n","histories = []\n","for i in range(l):\n","  tmp_grid = {}\n","  for item, value in params_grid.items():\n","    tmp_grid[item] = value[i]\n","  \n","  print(f\"experiment: {tmp_grid}\\n\")\n","\n","  histories.append(run_experiment(**fixed_params, **tmp_grid))\n","  history_metadata.append(tmp_grid)\n","\n","  with open(history_name, \"wb\" ) as f:\n","    pickle.dump( histories, f)\n","  with open(\"metadata\" + history_name, \"wb\" ) as f:\n","    pickle.dump( \"metadata\" + history_name, f)\n","\n","  # check point on drive\n","  !zip -r ../gdrive/MyDrive/Ann_Challenge/Experiments/HistCheckpoint.zip {history_name}\n","  !zip -r ../gdrive/MyDrive/Ann_Challenge/Experiments/MetaCheckpoint.zip {\"metadata\" + history_name}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l5eAMJAsOMyZ","executionInfo":{"status":"ok","timestamp":1669215586811,"user_tz":-60,"elapsed":3833383,"user":{"displayName":"Gianmario C","userId":"01154362426832162044"}},"outputId":"696a80e8-9845-449b-d9d6-03daa76a92d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["experiment: {'DROPOUT_RATE_CLASSIFIER': 0.3, 'DROPOUT': 0.2}\n","\n","Found 3624 files belonging to 8 classes.\n","Found 719 files belonging to 8 classes.\n","\n","Pre training activated\n","\n","Base model before Pretraining\n","Trainable: \t\t0\n","Non Trainable:  \t17673823\n","Epoch 1/500\n","57/57 [==============================] - 29s 266ms/step - loss: 2.3618 - accuracy: 0.3761 - val_loss: 1.3795 - val_accuracy: 0.4771\n","Epoch 2/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.8980 - accuracy: 0.5105 - val_loss: 1.2930 - val_accuracy: 0.5216\n","Epoch 3/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.7711 - accuracy: 0.5433 - val_loss: 1.2280 - val_accuracy: 0.5452\n","Epoch 4/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.6829 - accuracy: 0.5637 - val_loss: 1.1936 - val_accuracy: 0.5647\n","Epoch 5/500\n","57/57 [==============================] - 8s 140ms/step - loss: 1.6434 - accuracy: 0.5872 - val_loss: 1.1433 - val_accuracy: 0.5855\n","Epoch 6/500\n","57/57 [==============================] - 8s 135ms/step - loss: 1.5534 - accuracy: 0.5966 - val_loss: 1.1264 - val_accuracy: 0.5800\n","Epoch 7/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.5347 - accuracy: 0.6079 - val_loss: 1.0970 - val_accuracy: 0.5911\n","Epoch 8/500\n","57/57 [==============================] - 8s 140ms/step - loss: 1.5153 - accuracy: 0.6029 - val_loss: 1.1007 - val_accuracy: 0.5994\n","Epoch 9/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.5040 - accuracy: 0.5955 - val_loss: 1.0761 - val_accuracy: 0.6078\n","Epoch 10/500\n","57/57 [==============================] - 8s 136ms/step - loss: 1.4623 - accuracy: 0.6181 - val_loss: 1.0775 - val_accuracy: 0.6078\n","Epoch 11/500\n","57/57 [==============================] - 8s 140ms/step - loss: 1.4718 - accuracy: 0.6162 - val_loss: 1.0530 - val_accuracy: 0.6300\n","Epoch 12/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.4274 - accuracy: 0.6349 - val_loss: 1.0474 - val_accuracy: 0.6231\n","Epoch 13/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.4269 - accuracy: 0.6250 - val_loss: 1.0448 - val_accuracy: 0.6217\n","Epoch 14/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.4382 - accuracy: 0.6206 - val_loss: 1.0421 - val_accuracy: 0.6161\n","Epoch 15/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.3988 - accuracy: 0.6380 - val_loss: 1.0173 - val_accuracy: 0.6245\n","Epoch 16/500\n","57/57 [==============================] - 8s 136ms/step - loss: 1.4117 - accuracy: 0.6360 - val_loss: 1.0166 - val_accuracy: 0.6259\n","Epoch 17/500\n","57/57 [==============================] - 8s 141ms/step - loss: 1.3989 - accuracy: 0.6313 - val_loss: 0.9984 - val_accuracy: 0.6314\n","Epoch 18/500\n","57/57 [==============================] - 8s 140ms/step - loss: 1.3892 - accuracy: 0.6451 - val_loss: 0.9829 - val_accuracy: 0.6370\n","Epoch 19/500\n","57/57 [==============================] - 8s 140ms/step - loss: 1.3928 - accuracy: 0.6363 - val_loss: 0.9987 - val_accuracy: 0.6398\n","Epoch 20/500\n","57/57 [==============================] - 8s 136ms/step - loss: 1.3743 - accuracy: 0.6476 - val_loss: 1.0081 - val_accuracy: 0.6314\n","Epoch 21/500\n","57/57 [==============================] - 8s 141ms/step - loss: 1.3367 - accuracy: 0.6512 - val_loss: 0.9748 - val_accuracy: 0.6439\n","Epoch 22/500\n","57/57 [==============================] - 8s 140ms/step - loss: 1.3387 - accuracy: 0.6636 - val_loss: 0.9741 - val_accuracy: 0.6467\n","Epoch 23/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.3667 - accuracy: 0.6462 - val_loss: 0.9710 - val_accuracy: 0.6426\n","Epoch 24/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.3469 - accuracy: 0.6551 - val_loss: 0.9746 - val_accuracy: 0.6453\n","Epoch 25/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.3320 - accuracy: 0.6523 - val_loss: 0.9712 - val_accuracy: 0.6412\n","Epoch 26/500\n","57/57 [==============================] - 8s 141ms/step - loss: 1.3352 - accuracy: 0.6534 - val_loss: 0.9495 - val_accuracy: 0.6592\n","Epoch 27/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.3300 - accuracy: 0.6584 - val_loss: 0.9471 - val_accuracy: 0.6537\n","Epoch 28/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.3195 - accuracy: 0.6664 - val_loss: 0.9605 - val_accuracy: 0.6495\n","Epoch 29/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.3452 - accuracy: 0.6487 - val_loss: 0.9601 - val_accuracy: 0.6467\n","Epoch 30/500\n","57/57 [==============================] - 8s 136ms/step - loss: 1.3252 - accuracy: 0.6620 - val_loss: 0.9387 - val_accuracy: 0.6537\n","Epoch 31/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.2877 - accuracy: 0.6578 - val_loss: 0.9266 - val_accuracy: 0.6551\n","Epoch 32/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2973 - accuracy: 0.6672 - val_loss: 0.9488 - val_accuracy: 0.6537\n","Epoch 33/500\n","57/57 [==============================] - 8s 142ms/step - loss: 1.2928 - accuracy: 0.6609 - val_loss: 0.9205 - val_accuracy: 0.6676\n","Epoch 34/500\n","57/57 [==============================] - 8s 136ms/step - loss: 1.3027 - accuracy: 0.6581 - val_loss: 0.9376 - val_accuracy: 0.6551\n","Epoch 35/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.3063 - accuracy: 0.6628 - val_loss: 0.9409 - val_accuracy: 0.6523\n","Epoch 36/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.2855 - accuracy: 0.6639 - val_loss: 0.9405 - val_accuracy: 0.6495\n","Epoch 37/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.3007 - accuracy: 0.6631 - val_loss: 0.9411 - val_accuracy: 0.6551\n","Epoch 38/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.3050 - accuracy: 0.6611 - val_loss: 0.9250 - val_accuracy: 0.6606\n","Epoch 39/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.3083 - accuracy: 0.6639 - val_loss: 0.9425 - val_accuracy: 0.6523\n","Epoch 40/500\n","57/57 [==============================] - 8s 141ms/step - loss: 1.2923 - accuracy: 0.6623 - val_loss: 0.9115 - val_accuracy: 0.6718\n","Epoch 41/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2857 - accuracy: 0.6664 - val_loss: 0.9203 - val_accuracy: 0.6634\n","Epoch 42/500\n","57/57 [==============================] - 8s 140ms/step - loss: 1.2927 - accuracy: 0.6620 - val_loss: 0.8930 - val_accuracy: 0.6732\n","Epoch 43/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2870 - accuracy: 0.6609 - val_loss: 0.9091 - val_accuracy: 0.6648\n","Epoch 44/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2804 - accuracy: 0.6600 - val_loss: 0.9088 - val_accuracy: 0.6648\n","Epoch 45/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2862 - accuracy: 0.6631 - val_loss: 0.9061 - val_accuracy: 0.6606\n","Epoch 46/500\n","57/57 [==============================] - 8s 141ms/step - loss: 1.3013 - accuracy: 0.6592 - val_loss: 0.9136 - val_accuracy: 0.6759\n","Epoch 47/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.2638 - accuracy: 0.6769 - val_loss: 0.9215 - val_accuracy: 0.6495\n","Epoch 48/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2736 - accuracy: 0.6689 - val_loss: 0.9210 - val_accuracy: 0.6704\n","Epoch 49/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.2517 - accuracy: 0.6730 - val_loss: 0.9161 - val_accuracy: 0.6690\n","Epoch 50/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2571 - accuracy: 0.6692 - val_loss: 0.9103 - val_accuracy: 0.6718\n","Epoch 51/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.2821 - accuracy: 0.6556 - val_loss: 0.9134 - val_accuracy: 0.6676\n","Epoch 52/500\n","57/57 [==============================] - 8s 142ms/step - loss: 1.2683 - accuracy: 0.6725 - val_loss: 0.8989 - val_accuracy: 0.6815\n","Epoch 53/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2776 - accuracy: 0.6672 - val_loss: 0.9048 - val_accuracy: 0.6718\n","Epoch 54/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.2582 - accuracy: 0.6791 - val_loss: 0.8931 - val_accuracy: 0.6732\n","Epoch 55/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2736 - accuracy: 0.6733 - val_loss: 0.8923 - val_accuracy: 0.6815\n","Epoch 56/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2517 - accuracy: 0.6769 - val_loss: 0.9048 - val_accuracy: 0.6634\n","Epoch 57/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2689 - accuracy: 0.6708 - val_loss: 0.9147 - val_accuracy: 0.6648\n","Epoch 58/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2555 - accuracy: 0.6700 - val_loss: 0.9028 - val_accuracy: 0.6787\n","Epoch 59/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.2843 - accuracy: 0.6700 - val_loss: 0.8949 - val_accuracy: 0.6759\n","Epoch 60/500\n","57/57 [==============================] - 8s 141ms/step - loss: 1.2532 - accuracy: 0.6752 - val_loss: 0.8806 - val_accuracy: 0.6829\n","Epoch 61/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2592 - accuracy: 0.6752 - val_loss: 0.8814 - val_accuracy: 0.6801\n","Epoch 62/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2366 - accuracy: 0.6802 - val_loss: 0.8969 - val_accuracy: 0.6745\n","Epoch 63/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.2460 - accuracy: 0.6796 - val_loss: 0.8900 - val_accuracy: 0.6815\n","Epoch 64/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.2544 - accuracy: 0.6733 - val_loss: 0.9021 - val_accuracy: 0.6704\n","Epoch 65/500\n","57/57 [==============================] - 8s 142ms/step - loss: 1.2648 - accuracy: 0.6747 - val_loss: 0.8968 - val_accuracy: 0.6885\n","Epoch 66/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2554 - accuracy: 0.6738 - val_loss: 0.9123 - val_accuracy: 0.6676\n","Epoch 67/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2838 - accuracy: 0.6625 - val_loss: 0.9014 - val_accuracy: 0.6759\n","Epoch 68/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2287 - accuracy: 0.6703 - val_loss: 0.9378 - val_accuracy: 0.6634\n","Epoch 69/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2471 - accuracy: 0.6741 - val_loss: 0.9020 - val_accuracy: 0.6773\n","Epoch 70/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2542 - accuracy: 0.6774 - val_loss: 0.8896 - val_accuracy: 0.6787\n","Epoch 71/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.2502 - accuracy: 0.6758 - val_loss: 0.9158 - val_accuracy: 0.6579\n","Epoch 72/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2385 - accuracy: 0.6816 - val_loss: 0.8874 - val_accuracy: 0.6718\n","Epoch 73/500\n","57/57 [==============================] - 8s 141ms/step - loss: 1.2470 - accuracy: 0.6780 - val_loss: 0.8698 - val_accuracy: 0.6940\n","Epoch 74/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.2461 - accuracy: 0.6788 - val_loss: 0.8747 - val_accuracy: 0.6871\n","Epoch 75/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.2312 - accuracy: 0.6736 - val_loss: 0.8729 - val_accuracy: 0.6885\n","Epoch 76/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2719 - accuracy: 0.6678 - val_loss: 0.8734 - val_accuracy: 0.6885\n","Epoch 77/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2375 - accuracy: 0.6893 - val_loss: 0.8739 - val_accuracy: 0.6885\n","Epoch 78/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.2441 - accuracy: 0.6752 - val_loss: 0.8797 - val_accuracy: 0.6829\n","Epoch 79/500\n","57/57 [==============================] - 8s 144ms/step - loss: 1.2088 - accuracy: 0.6810 - val_loss: 0.8695 - val_accuracy: 0.6815\n","Epoch 80/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.2639 - accuracy: 0.6675 - val_loss: 0.8653 - val_accuracy: 0.6940\n","Epoch 81/500\n","57/57 [==============================] - 8s 144ms/step - loss: 1.2416 - accuracy: 0.6700 - val_loss: 0.8908 - val_accuracy: 0.6843\n","Epoch 82/500\n","57/57 [==============================] - 8s 140ms/step - loss: 1.2513 - accuracy: 0.6769 - val_loss: 0.8568 - val_accuracy: 0.6871\n","Epoch 83/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.2579 - accuracy: 0.6675 - val_loss: 0.8770 - val_accuracy: 0.6829\n","Epoch 84/500\n","57/57 [==============================] - 8s 140ms/step - loss: 1.2482 - accuracy: 0.6738 - val_loss: 0.8840 - val_accuracy: 0.6815\n","Epoch 85/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2369 - accuracy: 0.6744 - val_loss: 0.8818 - val_accuracy: 0.6857\n","Epoch 86/500\n","57/57 [==============================] - 8s 142ms/step - loss: 1.2760 - accuracy: 0.6777 - val_loss: 0.8634 - val_accuracy: 0.6996\n","Epoch 87/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2575 - accuracy: 0.6714 - val_loss: 0.8583 - val_accuracy: 0.6926\n","Epoch 88/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.2372 - accuracy: 0.6744 - val_loss: 0.8648 - val_accuracy: 0.6885\n","Epoch 89/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2171 - accuracy: 0.6871 - val_loss: 0.8774 - val_accuracy: 0.6787\n","Epoch 90/500\n","57/57 [==============================] - 8s 145ms/step - loss: 1.2131 - accuracy: 0.6965 - val_loss: 0.8581 - val_accuracy: 0.6926\n","Epoch 91/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.1941 - accuracy: 0.6918 - val_loss: 0.8666 - val_accuracy: 0.6871\n","Epoch 92/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.2313 - accuracy: 0.6774 - val_loss: 0.8860 - val_accuracy: 0.6843\n","Epoch 93/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.2391 - accuracy: 0.6760 - val_loss: 0.8913 - val_accuracy: 0.6745\n","Epoch 94/500\n","57/57 [==============================] - 8s 144ms/step - loss: 1.2644 - accuracy: 0.6697 - val_loss: 0.8628 - val_accuracy: 0.6759\n","Epoch 95/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2234 - accuracy: 0.6816 - val_loss: 0.8752 - val_accuracy: 0.6843\n","Epoch 96/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2476 - accuracy: 0.6772 - val_loss: 0.8579 - val_accuracy: 0.6898\n","Epoch 97/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2381 - accuracy: 0.6827 - val_loss: 0.8809 - val_accuracy: 0.6843\n","Epoch 98/500\n","57/57 [==============================] - 8s 138ms/step - loss: 1.2321 - accuracy: 0.6791 - val_loss: 0.8706 - val_accuracy: 0.6885\n","Epoch 99/500\n","57/57 [==============================] - 8s 137ms/step - loss: 1.2436 - accuracy: 0.6738 - val_loss: 0.8621 - val_accuracy: 0.6871\n","Epoch 100/500\n","57/57 [==============================] - 8s 139ms/step - loss: 1.2489 - accuracy: 0.6766 - val_loss: 0.8697 - val_accuracy: 0.6982\n","Epoch 101/500\n","57/57 [==============================] - 8s 142ms/step - loss: 1.2387 - accuracy: 0.6865 - val_loss: 0.8624 - val_accuracy: 0.6843\n","\n","Pretrain ended with val accuracy: 0.6995827555656433\n","\n","Before Freeze\n","Trainable: \t\t17548616\n","Non Trainable:  \t125207\n","\n","netwrok size 475 freezed layers -> 23\n","\n","After Freeze\n","Trainable: \t\t17419108\n","Non Trainable:  \t254715\n","\n","Compiled model for fine tuning\n","Trainable: \t\t17433452\n","Non Trainable:  \t254715\n","Epoch 1/500\n","57/57 [==============================] - 40s 394ms/step - loss: 8.9039 - accuracy: 0.7014 - val_loss: 8.5658 - val_accuracy: 0.7135\n","Epoch 2/500\n","57/57 [==============================] - 19s 335ms/step - loss: 8.7720 - accuracy: 0.7318 - val_loss: 8.4924 - val_accuracy: 0.7204\n","Epoch 3/500\n","57/57 [==============================] - 19s 337ms/step - loss: 8.6585 - accuracy: 0.7425 - val_loss: 8.4172 - val_accuracy: 0.7260\n","Epoch 4/500\n","57/57 [==============================] - 19s 336ms/step - loss: 8.5409 - accuracy: 0.7608 - val_loss: 8.3011 - val_accuracy: 0.7594\n","Epoch 5/500\n","57/57 [==============================] - 19s 334ms/step - loss: 8.4574 - accuracy: 0.7679 - val_loss: 8.2890 - val_accuracy: 0.7330\n","Epoch 6/500\n","57/57 [==============================] - 19s 338ms/step - loss: 8.3676 - accuracy: 0.7792 - val_loss: 8.1782 - val_accuracy: 0.7636\n","Epoch 7/500\n","57/57 [==============================] - 19s 337ms/step - loss: 8.2970 - accuracy: 0.7870 - val_loss: 8.1309 - val_accuracy: 0.7677\n","Epoch 8/500\n","57/57 [==============================] - 19s 337ms/step - loss: 8.2144 - accuracy: 0.7939 - val_loss: 8.0536 - val_accuracy: 0.7844\n","Epoch 9/500\n","57/57 [==============================] - 19s 335ms/step - loss: 8.1493 - accuracy: 0.8046 - val_loss: 8.0076 - val_accuracy: 0.7803\n","Epoch 10/500\n","57/57 [==============================] - 19s 337ms/step - loss: 8.0575 - accuracy: 0.8159 - val_loss: 7.9447 - val_accuracy: 0.7900\n","Epoch 11/500\n","57/57 [==============================] - 19s 335ms/step - loss: 7.9927 - accuracy: 0.8226 - val_loss: 7.8857 - val_accuracy: 0.7900\n","Epoch 12/500\n","57/57 [==============================] - 20s 349ms/step - loss: 7.9068 - accuracy: 0.8386 - val_loss: 7.8479 - val_accuracy: 0.7969\n","Epoch 13/500\n","57/57 [==============================] - 19s 335ms/step - loss: 7.8594 - accuracy: 0.8342 - val_loss: 7.7871 - val_accuracy: 0.7955\n","Epoch 14/500\n","57/57 [==============================] - 19s 338ms/step - loss: 7.7583 - accuracy: 0.8491 - val_loss: 7.7270 - val_accuracy: 0.8039\n","Epoch 15/500\n","57/57 [==============================] - 19s 334ms/step - loss: 7.6989 - accuracy: 0.8612 - val_loss: 7.7016 - val_accuracy: 0.7997\n","Epoch 16/500\n","57/57 [==============================] - 20s 348ms/step - loss: 7.6400 - accuracy: 0.8595 - val_loss: 7.6466 - val_accuracy: 0.8095\n","Epoch 17/500\n","57/57 [==============================] - 19s 339ms/step - loss: 7.5687 - accuracy: 0.8714 - val_loss: 7.5659 - val_accuracy: 0.8206\n","Epoch 18/500\n","57/57 [==============================] - 19s 336ms/step - loss: 7.5065 - accuracy: 0.8744 - val_loss: 7.5277 - val_accuracy: 0.8108\n","Epoch 19/500\n","57/57 [==============================] - 20s 344ms/step - loss: 7.4531 - accuracy: 0.8744 - val_loss: 7.4914 - val_accuracy: 0.8067\n","Epoch 20/500\n","57/57 [==============================] - 19s 334ms/step - loss: 7.4009 - accuracy: 0.8747 - val_loss: 7.4211 - val_accuracy: 0.8192\n","Epoch 21/500\n","57/57 [==============================] - 20s 345ms/step - loss: 7.3427 - accuracy: 0.8797 - val_loss: 7.3845 - val_accuracy: 0.8164\n","Epoch 22/500\n","57/57 [==============================] - 19s 336ms/step - loss: 7.2763 - accuracy: 0.8869 - val_loss: 7.3293 - val_accuracy: 0.8206\n","Epoch 23/500\n","57/57 [==============================] - 19s 334ms/step - loss: 7.2213 - accuracy: 0.8863 - val_loss: 7.3081 - val_accuracy: 0.8150\n","Epoch 24/500\n","57/57 [==============================] - 20s 348ms/step - loss: 7.1550 - accuracy: 0.8979 - val_loss: 7.2345 - val_accuracy: 0.8303\n","Epoch 25/500\n","57/57 [==============================] - 19s 338ms/step - loss: 7.1235 - accuracy: 0.8938 - val_loss: 7.1852 - val_accuracy: 0.8331\n","Epoch 26/500\n","57/57 [==============================] - 19s 334ms/step - loss: 7.0421 - accuracy: 0.9007 - val_loss: 7.1375 - val_accuracy: 0.8331\n","Epoch 27/500\n","57/57 [==============================] - 20s 343ms/step - loss: 7.0046 - accuracy: 0.8990 - val_loss: 7.1125 - val_accuracy: 0.8206\n","Epoch 28/500\n","57/57 [==============================] - 19s 336ms/step - loss: 6.9507 - accuracy: 0.9042 - val_loss: 7.0831 - val_accuracy: 0.8220\n","Epoch 29/500\n","57/57 [==============================] - 19s 338ms/step - loss: 6.8726 - accuracy: 0.9158 - val_loss: 7.0063 - val_accuracy: 0.8345\n","Epoch 30/500\n","57/57 [==============================] - 19s 335ms/step - loss: 6.8254 - accuracy: 0.9156 - val_loss: 6.9917 - val_accuracy: 0.8331\n","Epoch 31/500\n","57/57 [==============================] - 20s 344ms/step - loss: 6.7825 - accuracy: 0.9139 - val_loss: 6.9529 - val_accuracy: 0.8303\n","Epoch 32/500\n","57/57 [==============================] - 19s 339ms/step - loss: 6.7210 - accuracy: 0.9233 - val_loss: 6.8963 - val_accuracy: 0.8428\n","Epoch 33/500\n","57/57 [==============================] - 19s 335ms/step - loss: 6.6814 - accuracy: 0.9238 - val_loss: 6.8506 - val_accuracy: 0.8401\n","Epoch 34/500\n","57/57 [==============================] - 20s 343ms/step - loss: 6.6361 - accuracy: 0.9222 - val_loss: 6.8173 - val_accuracy: 0.8401\n","Epoch 35/500\n","57/57 [==============================] - 19s 339ms/step - loss: 6.5618 - accuracy: 0.9283 - val_loss: 6.7594 - val_accuracy: 0.8470\n","Epoch 36/500\n","57/57 [==============================] - 19s 335ms/step - loss: 6.5186 - accuracy: 0.9305 - val_loss: 6.7279 - val_accuracy: 0.8470\n","Epoch 37/500\n","57/57 [==============================] - 20s 344ms/step - loss: 6.4865 - accuracy: 0.9266 - val_loss: 6.7134 - val_accuracy: 0.8373\n","Epoch 38/500\n","57/57 [==============================] - 19s 334ms/step - loss: 6.4334 - accuracy: 0.9338 - val_loss: 6.6351 - val_accuracy: 0.8442\n","Epoch 39/500\n","57/57 [==============================] - 19s 335ms/step - loss: 6.3814 - accuracy: 0.9368 - val_loss: 6.6102 - val_accuracy: 0.8456\n","Epoch 40/500\n","57/57 [==============================] - 19s 339ms/step - loss: 6.3287 - accuracy: 0.9365 - val_loss: 6.5381 - val_accuracy: 0.8540\n","Epoch 41/500\n","57/57 [==============================] - 20s 343ms/step - loss: 6.2791 - accuracy: 0.9390 - val_loss: 6.5434 - val_accuracy: 0.8470\n","Epoch 42/500\n","57/57 [==============================] - 19s 337ms/step - loss: 6.2249 - accuracy: 0.9459 - val_loss: 6.5384 - val_accuracy: 0.8303\n","Epoch 43/500\n","57/57 [==============================] - 19s 335ms/step - loss: 6.2007 - accuracy: 0.9407 - val_loss: 6.4594 - val_accuracy: 0.8456\n","Epoch 44/500\n","57/57 [==============================] - 20s 345ms/step - loss: 6.1443 - accuracy: 0.9459 - val_loss: 6.4115 - val_accuracy: 0.8470\n","Epoch 45/500\n","57/57 [==============================] - 19s 334ms/step - loss: 6.0977 - accuracy: 0.9476 - val_loss: 6.3742 - val_accuracy: 0.8484\n","Epoch 46/500\n","57/57 [==============================] - 19s 334ms/step - loss: 6.0567 - accuracy: 0.9481 - val_loss: 6.3513 - val_accuracy: 0.8428\n","Epoch 47/500\n","57/57 [==============================] - 20s 345ms/step - loss: 6.0137 - accuracy: 0.9481 - val_loss: 6.2827 - val_accuracy: 0.8526\n","Epoch 48/500\n","57/57 [==============================] - 19s 338ms/step - loss: 5.9700 - accuracy: 0.9517 - val_loss: 6.2459 - val_accuracy: 0.8567\n","Epoch 49/500\n","57/57 [==============================] - 19s 334ms/step - loss: 5.9279 - accuracy: 0.9498 - val_loss: 6.2372 - val_accuracy: 0.8498\n","Epoch 50/500\n","57/57 [==============================] - 19s 338ms/step - loss: 5.8665 - accuracy: 0.9586 - val_loss: 6.1613 - val_accuracy: 0.8595\n","Epoch 51/500\n","57/57 [==============================] - 20s 345ms/step - loss: 5.8218 - accuracy: 0.9611 - val_loss: 6.1572 - val_accuracy: 0.8498\n","Epoch 52/500\n","57/57 [==============================] - 19s 339ms/step - loss: 5.7990 - accuracy: 0.9550 - val_loss: 6.0861 - val_accuracy: 0.8623\n","Epoch 53/500\n","57/57 [==============================] - 19s 335ms/step - loss: 5.7437 - accuracy: 0.9616 - val_loss: 6.0715 - val_accuracy: 0.8554\n","Epoch 54/500\n","57/57 [==============================] - 20s 346ms/step - loss: 5.6918 - accuracy: 0.9622 - val_loss: 6.0181 - val_accuracy: 0.8540\n","Epoch 55/500\n","57/57 [==============================] - 19s 336ms/step - loss: 5.6467 - accuracy: 0.9636 - val_loss: 6.0112 - val_accuracy: 0.8567\n","Epoch 56/500\n","57/57 [==============================] - 19s 335ms/step - loss: 5.6078 - accuracy: 0.9677 - val_loss: 5.9639 - val_accuracy: 0.8526\n","Epoch 57/500\n","57/57 [==============================] - 20s 346ms/step - loss: 5.5706 - accuracy: 0.9619 - val_loss: 5.8989 - val_accuracy: 0.8609\n","Epoch 58/500\n","57/57 [==============================] - 19s 337ms/step - loss: 5.5487 - accuracy: 0.9650 - val_loss: 5.8941 - val_accuracy: 0.8595\n","Epoch 59/500\n","57/57 [==============================] - 19s 336ms/step - loss: 5.4797 - accuracy: 0.9710 - val_loss: 5.8786 - val_accuracy: 0.8567\n","Epoch 60/500\n","57/57 [==============================] - 19s 340ms/step - loss: 5.4561 - accuracy: 0.9680 - val_loss: 5.8168 - val_accuracy: 0.8637\n","Epoch 61/500\n","57/57 [==============================] - 20s 350ms/step - loss: 5.4014 - accuracy: 0.9702 - val_loss: 5.7660 - val_accuracy: 0.8665\n","Epoch 62/500\n","57/57 [==============================] - 19s 336ms/step - loss: 5.3750 - accuracy: 0.9696 - val_loss: 5.7256 - val_accuracy: 0.8637\n","Epoch 63/500\n","57/57 [==============================] - 19s 339ms/step - loss: 5.3324 - accuracy: 0.9683 - val_loss: 5.6946 - val_accuracy: 0.8679\n","Epoch 64/500\n","57/57 [==============================] - 20s 346ms/step - loss: 5.2990 - accuracy: 0.9674 - val_loss: 5.7236 - val_accuracy: 0.8401\n","Epoch 65/500\n","57/57 [==============================] - 19s 335ms/step - loss: 5.2546 - accuracy: 0.9702 - val_loss: 5.6150 - val_accuracy: 0.8623\n","Epoch 66/500\n","57/57 [==============================] - 19s 336ms/step - loss: 5.2113 - accuracy: 0.9727 - val_loss: 5.5987 - val_accuracy: 0.8637\n","Epoch 67/500\n","57/57 [==============================] - 20s 346ms/step - loss: 5.1770 - accuracy: 0.9741 - val_loss: 5.5562 - val_accuracy: 0.8679\n","Epoch 68/500\n","57/57 [==============================] - 19s 336ms/step - loss: 5.1269 - accuracy: 0.9793 - val_loss: 5.4995 - val_accuracy: 0.8637\n","Epoch 69/500\n","57/57 [==============================] - 19s 335ms/step - loss: 5.0930 - accuracy: 0.9765 - val_loss: 5.5278 - val_accuracy: 0.8595\n","Epoch 70/500\n","57/57 [==============================] - 19s 335ms/step - loss: 5.0544 - accuracy: 0.9754 - val_loss: 5.4591 - val_accuracy: 0.8623\n","Epoch 71/500\n","57/57 [==============================] - 20s 345ms/step - loss: 5.0123 - accuracy: 0.9749 - val_loss: 5.4329 - val_accuracy: 0.8665\n","Epoch 72/500\n","57/57 [==============================] - 19s 336ms/step - loss: 4.9890 - accuracy: 0.9754 - val_loss: 5.4038 - val_accuracy: 0.8665\n","Epoch 73/500\n","57/57 [==============================] - 19s 340ms/step - loss: 4.9486 - accuracy: 0.9774 - val_loss: 5.3515 - val_accuracy: 0.8748\n","Epoch 74/500\n","57/57 [==============================] - 19s 336ms/step - loss: 4.9162 - accuracy: 0.9765 - val_loss: 5.3169 - val_accuracy: 0.8734\n","Epoch 75/500\n","57/57 [==============================] - 20s 346ms/step - loss: 4.8740 - accuracy: 0.9782 - val_loss: 5.3036 - val_accuracy: 0.8693\n","Epoch 76/500\n","57/57 [==============================] - 19s 334ms/step - loss: 4.8328 - accuracy: 0.9799 - val_loss: 5.2429 - val_accuracy: 0.8734\n","Epoch 77/500\n","57/57 [==============================] - 19s 335ms/step - loss: 4.7975 - accuracy: 0.9788 - val_loss: 5.2381 - val_accuracy: 0.8609\n","Epoch 78/500\n","57/57 [==============================] - 20s 345ms/step - loss: 4.7580 - accuracy: 0.9823 - val_loss: 5.1891 - val_accuracy: 0.8651\n","Epoch 79/500\n","57/57 [==============================] - 19s 336ms/step - loss: 4.7305 - accuracy: 0.9807 - val_loss: 5.1821 - val_accuracy: 0.8623\n","Epoch 80/500\n","57/57 [==============================] - 19s 334ms/step - loss: 4.6995 - accuracy: 0.9774 - val_loss: 5.1823 - val_accuracy: 0.8567\n","Epoch 81/500\n","57/57 [==============================] - 19s 335ms/step - loss: 4.6525 - accuracy: 0.9832 - val_loss: 5.1162 - val_accuracy: 0.8693\n","Epoch 82/500\n","57/57 [==============================] - 20s 345ms/step - loss: 4.6155 - accuracy: 0.9821 - val_loss: 5.1003 - val_accuracy: 0.8651\n","Epoch 83/500\n","57/57 [==============================] - 19s 335ms/step - loss: 4.5878 - accuracy: 0.9832 - val_loss: 5.0489 - val_accuracy: 0.8679\n","Epoch 84/500\n","57/57 [==============================] - 19s 337ms/step - loss: 4.5481 - accuracy: 0.9837 - val_loss: 5.0030 - val_accuracy: 0.8762\n","Epoch 85/500\n","57/57 [==============================] - 20s 346ms/step - loss: 4.5090 - accuracy: 0.9857 - val_loss: 4.9760 - val_accuracy: 0.8734\n","Epoch 86/500\n","57/57 [==============================] - 19s 339ms/step - loss: 4.4748 - accuracy: 0.9862 - val_loss: 4.9253 - val_accuracy: 0.8790\n","Epoch 87/500\n","57/57 [==============================] - 19s 336ms/step - loss: 4.4351 - accuracy: 0.9892 - val_loss: 4.8985 - val_accuracy: 0.8762\n","Epoch 88/500\n","57/57 [==============================] - 19s 335ms/step - loss: 4.4087 - accuracy: 0.9845 - val_loss: 4.8646 - val_accuracy: 0.8762\n","Epoch 89/500\n","57/57 [==============================] - 20s 345ms/step - loss: 4.3752 - accuracy: 0.9848 - val_loss: 4.8404 - val_accuracy: 0.8734\n","Epoch 90/500\n","57/57 [==============================] - 19s 335ms/step - loss: 4.3436 - accuracy: 0.9840 - val_loss: 4.8387 - val_accuracy: 0.8707\n","Epoch 91/500\n","57/57 [==============================] - 19s 335ms/step - loss: 4.3056 - accuracy: 0.9873 - val_loss: 4.8020 - val_accuracy: 0.8734\n","Epoch 92/500\n","57/57 [==============================] - 20s 345ms/step - loss: 4.2752 - accuracy: 0.9876 - val_loss: 4.7565 - val_accuracy: 0.8720\n","Epoch 93/500\n","57/57 [==============================] - 19s 339ms/step - loss: 4.2482 - accuracy: 0.9848 - val_loss: 4.7173 - val_accuracy: 0.8832\n","Epoch 94/500\n","57/57 [==============================] - 19s 335ms/step - loss: 4.2062 - accuracy: 0.9870 - val_loss: 4.7316 - val_accuracy: 0.8693\n","Epoch 95/500\n","57/57 [==============================] - 19s 335ms/step - loss: 4.1800 - accuracy: 0.9862 - val_loss: 4.7062 - val_accuracy: 0.8720\n","Epoch 96/500\n","57/57 [==============================] - 20s 346ms/step - loss: 4.1450 - accuracy: 0.9884 - val_loss: 4.6425 - val_accuracy: 0.8720\n","Epoch 97/500\n","57/57 [==============================] - 19s 334ms/step - loss: 4.1163 - accuracy: 0.9873 - val_loss: 4.6289 - val_accuracy: 0.8707\n","Epoch 98/500\n","57/57 [==============================] - 19s 341ms/step - loss: 4.0926 - accuracy: 0.9837 - val_loss: 4.5575 - val_accuracy: 0.8818\n","Epoch 99/500\n","57/57 [==============================] - 20s 346ms/step - loss: 4.0519 - accuracy: 0.9873 - val_loss: 4.5907 - val_accuracy: 0.8734\n","Epoch 100/500\n","57/57 [==============================] - 19s 336ms/step - loss: 4.0196 - accuracy: 0.9876 - val_loss: 4.5420 - val_accuracy: 0.8679\n","Epoch 101/500\n","57/57 [==============================] - 19s 335ms/step - loss: 3.9823 - accuracy: 0.9901 - val_loss: 4.5022 - val_accuracy: 0.8720\n","Epoch 102/500\n","57/57 [==============================] - 20s 348ms/step - loss: 3.9644 - accuracy: 0.9865 - val_loss: 4.4611 - val_accuracy: 0.8734\n","Epoch 103/500\n","57/57 [==============================] - 19s 337ms/step - loss: 3.9407 - accuracy: 0.9848 - val_loss: 4.4610 - val_accuracy: 0.8679\n","Epoch 104/500\n","57/57 [==============================] - 19s 335ms/step - loss: 3.8986 - accuracy: 0.9898 - val_loss: 4.4101 - val_accuracy: 0.8790\n","Epoch 105/500\n","57/57 [==============================] - 19s 335ms/step - loss: 3.8828 - accuracy: 0.9843 - val_loss: 4.3677 - val_accuracy: 0.8776\n","Epoch 106/500\n","57/57 [==============================] - 20s 345ms/step - loss: 3.8451 - accuracy: 0.9870 - val_loss: 4.4216 - val_accuracy: 0.8637\n","Epoch 107/500\n","57/57 [==============================] - 19s 335ms/step - loss: 3.8014 - accuracy: 0.9903 - val_loss: 4.3128 - val_accuracy: 0.8720\n","Epoch 108/500\n","57/57 [==============================] - 19s 339ms/step - loss: 3.7685 - accuracy: 0.9931 - val_loss: 4.2829 - val_accuracy: 0.8846\n","Epoch 109/500\n","57/57 [==============================] - 20s 345ms/step - loss: 3.7449 - accuracy: 0.9901 - val_loss: 4.2595 - val_accuracy: 0.8707\n","Epoch 110/500\n","57/57 [==============================] - 19s 336ms/step - loss: 3.7224 - accuracy: 0.9898 - val_loss: 4.2473 - val_accuracy: 0.8748\n","Epoch 111/500\n","57/57 [==============================] - 19s 335ms/step - loss: 3.6845 - accuracy: 0.9920 - val_loss: 4.2212 - val_accuracy: 0.8707\n","Epoch 112/500\n","57/57 [==============================] - 19s 335ms/step - loss: 3.6532 - accuracy: 0.9925 - val_loss: 4.1696 - val_accuracy: 0.8707\n","Epoch 113/500\n","57/57 [==============================] - 20s 345ms/step - loss: 3.6288 - accuracy: 0.9912 - val_loss: 4.1522 - val_accuracy: 0.8762\n","Epoch 114/500\n","57/57 [==============================] - 19s 335ms/step - loss: 3.6029 - accuracy: 0.9887 - val_loss: 4.1719 - val_accuracy: 0.8581\n","Epoch 115/500\n","57/57 [==============================] - 19s 335ms/step - loss: 3.5838 - accuracy: 0.9881 - val_loss: 4.1093 - val_accuracy: 0.8720\n","Epoch 116/500\n","57/57 [==============================] - 19s 341ms/step - loss: 3.5407 - accuracy: 0.9939 - val_loss: 4.0441 - val_accuracy: 0.8776\n","Epoch 117/500\n","57/57 [==============================] - 19s 336ms/step - loss: 3.5097 - accuracy: 0.9931 - val_loss: 4.0243 - val_accuracy: 0.8762\n","Epoch 118/500\n","57/57 [==============================] - 19s 336ms/step - loss: 3.4847 - accuracy: 0.9931 - val_loss: 4.0428 - val_accuracy: 0.8734\n","Epoch 119/500\n","57/57 [==============================] - 19s 336ms/step - loss: 3.4627 - accuracy: 0.9898 - val_loss: 3.9890 - val_accuracy: 0.8762\n","Epoch 120/500\n","57/57 [==============================] - 20s 346ms/step - loss: 3.4370 - accuracy: 0.9903 - val_loss: 3.9753 - val_accuracy: 0.8734\n","Epoch 121/500\n","57/57 [==============================] - 19s 335ms/step - loss: 3.3945 - accuracy: 0.9950 - val_loss: 3.9678 - val_accuracy: 0.8720\n","Epoch 122/500\n","57/57 [==============================] - 19s 334ms/step - loss: 3.3763 - accuracy: 0.9928 - val_loss: 3.8933 - val_accuracy: 0.8790\n","Epoch 123/500\n","57/57 [==============================] - 20s 344ms/step - loss: 3.3486 - accuracy: 0.9917 - val_loss: 3.8959 - val_accuracy: 0.8707\n","Epoch 124/500\n","57/57 [==============================] - 19s 336ms/step - loss: 3.3162 - accuracy: 0.9942 - val_loss: 3.8886 - val_accuracy: 0.8748\n","Epoch 125/500\n","57/57 [==============================] - 19s 335ms/step - loss: 3.3063 - accuracy: 0.9898 - val_loss: 3.8548 - val_accuracy: 0.8790\n","Epoch 126/500\n","57/57 [==============================] - 19s 336ms/step - loss: 3.2619 - accuracy: 0.9961 - val_loss: 3.7815 - val_accuracy: 0.8846\n","Epoch 127/500\n","57/57 [==============================] - 19s 337ms/step - loss: 3.2445 - accuracy: 0.9931 - val_loss: 3.7782 - val_accuracy: 0.8776\n","Epoch 128/500\n","57/57 [==============================] - 19s 337ms/step - loss: 3.2190 - accuracy: 0.9920 - val_loss: 3.7606 - val_accuracy: 0.8790\n","Epoch 129/500\n","57/57 [==============================] - 19s 337ms/step - loss: 3.1895 - accuracy: 0.9937 - val_loss: 3.7575 - val_accuracy: 0.8707\n","Epoch 130/500\n","57/57 [==============================] - 20s 344ms/step - loss: 3.1718 - accuracy: 0.9923 - val_loss: 3.7377 - val_accuracy: 0.8665\n","Epoch 131/500\n","57/57 [==============================] - 19s 335ms/step - loss: 3.1420 - accuracy: 0.9925 - val_loss: 3.7268 - val_accuracy: 0.8609\n","Epoch 132/500\n","57/57 [==============================] - 19s 335ms/step - loss: 3.1195 - accuracy: 0.9923 - val_loss: 3.6602 - val_accuracy: 0.8762\n","Epoch 133/500\n","57/57 [==============================] - 20s 347ms/step - loss: 3.0982 - accuracy: 0.9931 - val_loss: 3.6708 - val_accuracy: 0.8748\n","\n"," ** GOOD MODEL FOUND **\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["  adding: history_list1669211751.p (deflated 59%)\n","  adding: metadatahistory_list1669211751.p (stored 0%)\n"]}]},{"cell_type":"markdown","source":["# Save and evaluate part"],"metadata":{"id":"3s5JyXu6BDEc"}},{"cell_type":"code","source":["!zip -r ../gdrive/MyDrive/Ann_Challenge/Experiments/Model088.zip Model_name16692059570.8873"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M6ixB5gBGq3q","executionInfo":{"status":"ok","timestamp":1669206088242,"user_tz":-60,"elapsed":12596,"user":{"displayName":"Gianmario C","userId":"01154362426832162044"}},"outputId":"ef3e4a8c-2d9e-478c-a8c5-9e86a30e7470"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: Model_name16692059570.8873/ (stored 0%)\n","  adding: Model_name16692059570.8873/variables/ (stored 0%)\n","  adding: Model_name16692059570.8873/variables/variables.index (deflated 78%)\n","  adding: Model_name16692059570.8873/variables/variables.data-00000-of-00001 (deflated 7%)\n","  adding: Model_name16692059570.8873/assets/ (stored 0%)\n","  adding: Model_name16692059570.8873/saved_model.pb (deflated 92%)\n","  adding: Model_name16692059570.8873/keras_metadata.pb (deflated 96%)\n"]}]},{"cell_type":"code","source":["!zip -r ../gdrive/MyDrive/Ann_Challenge/Experiments/Model009B.zip Model_name16691224010.9054"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcYvUYS7HUJm","executionInfo":{"status":"ok","timestamp":1669133628931,"user_tz":-60,"elapsed":14030,"user":{"displayName":"Gianmario C","userId":"01154362426832162044"}},"outputId":"285b3f70-1858-46f7-ac01-b35669c4f974"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: Model_name16691224010.9054/ (stored 0%)\n","  adding: Model_name16691224010.9054/saved_model.pb (deflated 92%)\n","  adding: Model_name16691224010.9054/variables/ (stored 0%)\n","  adding: Model_name16691224010.9054/variables/variables.data-00000-of-00001 (deflated 7%)\n","  adding: Model_name16691224010.9054/variables/variables.index (deflated 78%)\n","  adding: Model_name16691224010.9054/keras_metadata.pb (deflated 96%)\n","  adding: Model_name16691224010.9054/assets/ (stored 0%)\n"]}]},{"cell_type":"code","source":["history_metadata"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1RCnecXmHzj2","executionInfo":{"status":"ok","timestamp":1669133714836,"user_tz":-60,"elapsed":3,"user":{"displayName":"Gianmario C","userId":"01154362426832162044"}},"outputId":"e0256fff-3bfc-4ead-c653-599e86acd8c8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'REGULARIZER': None, 'DROPOUT': 0.0, 'DROPOUT_RATE_CLASSIFIER': 0.0},\n"," {'REGULARIZER': None, 'DROPOUT': 0.0, 'DROPOUT_RATE_CLASSIFIER': 0.2},\n"," {'REGULARIZER': None, 'DROPOUT': 0.0, 'DROPOUT_RATE_CLASSIFIER': 0.4},\n"," {'REGULARIZER': None, 'DROPOUT': 0.4, 'DROPOUT_RATE_CLASSIFIER': 0.0},\n"," {'REGULARIZER': None, 'DROPOUT': 0.4, 'DROPOUT_RATE_CLASSIFIER': 0.2},\n"," {'REGULARIZER': None, 'DROPOUT': 0.4, 'DROPOUT_RATE_CLASSIFIER': 0.4},\n"," {'REGULARIZER': <keras.regularizers.L2 at 0x7fe82f0c70d0>,\n","  'DROPOUT': 0.0,\n","  'DROPOUT_RATE_CLASSIFIER': 0.0},\n"," {'REGULARIZER': <keras.regularizers.L2 at 0x7fe82f0c70d0>,\n","  'DROPOUT': 0.0,\n","  'DROPOUT_RATE_CLASSIFIER': 0.2},\n"," {'REGULARIZER': <keras.regularizers.L2 at 0x7fe82f0c70d0>,\n","  'DROPOUT': 0.0,\n","  'DROPOUT_RATE_CLASSIFIER': 0.4},\n"," {'REGULARIZER': <keras.regularizers.L2 at 0x7fe82f0c70d0>,\n","  'DROPOUT': 0.4,\n","  'DROPOUT_RATE_CLASSIFIER': 0.0},\n"," {'REGULARIZER': <keras.regularizers.L2 at 0x7fe82f0c70d0>,\n","  'DROPOUT': 0.4,\n","  'DROPOUT_RATE_CLASSIFIER': 0.2},\n"," {'REGULARIZER': <keras.regularizers.L2 at 0x7fe82f0c70d0>,\n","  'DROPOUT': 0.4,\n","  'DROPOUT_RATE_CLASSIFIER': 0.4}]"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["history_name =  f\"history_list{int(time.time())}.p\"\n","with open(history_name, \"wb\" ) as f:\n","  pickle.dump( histories, f)\n","with open(\"metadata\" + history_name, \"wb\" ) as f:\n","  pickle.dump( \"metadata\" + history_name, f)"],"metadata":{"id":"wU6axNa-QR_v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","#files.download(history_name)\n","files.download(\"metadata\" + history_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"PLeVbkdmqPNQ","executionInfo":{"status":"ok","timestamp":1669133379010,"user_tz":-60,"elapsed":4,"user":{"displayName":"Gianmario C","userId":"01154362426832162044"}},"outputId":"9790ba90-3113-4630-b139-0881d446f5b8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_b7eac518-79c7-4552-838e-d8a89be51c89\", \"metadatahistory_list1669133289.p\", 42)"]},"metadata":{}}]},{"cell_type":"code","source":["[np.max(x['val_accuracy']) for x,y in histories]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZsELa2LO0Vum","executionInfo":{"status":"ok","timestamp":1669215638132,"user_tz":-60,"elapsed":2264,"user":{"displayName":"Gianmario C","userId":"01154362426832162044"}},"outputId":"e1dd6ca3-d22f-41df-e692-1b50b3221fe6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.8845618963241577]"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["!zip -r ../gdrive/MyDrive/Ann_Challenge/Experiments/Model_zip_8846.zip Model_name16692154860.8846"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FfQlMaRZPEpz","executionInfo":{"status":"ok","timestamp":1669215920713,"user_tz":-60,"elapsed":14486,"user":{"displayName":"Gianmario C","userId":"01154362426832162044"}},"outputId":"bca55397-cfff-4c05-b7e7-4af76e4dc7b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: Model_name16692154860.8846/ (stored 0%)\n","  adding: Model_name16692154860.8846/variables/ (stored 0%)\n","  adding: Model_name16692154860.8846/variables/variables.index (deflated 78%)\n","  adding: Model_name16692154860.8846/variables/variables.data-00000-of-00001 (deflated 7%)\n","  adding: Model_name16692154860.8846/assets/ (stored 0%)\n","  adding: Model_name16692154860.8846/saved_model.pb (deflated 92%)\n","  adding: Model_name16692154860.8846/keras_metadata.pb (deflated 96%)\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n","import matplotlib.pyplot as plt\n","\n","def show_confusion(model, validation_dataset):\n","  Y_pred = model.predict(validation_dataset)\n","  y_pred = np.argmax(Y_pred, axis=1)\n","  y_test= np.concatenate([np.argmax(y, axis=1) for x, y in validation_dataset], axis=0)\n","\n","  cm = confusion_matrix(y_test, y_pred)\n","\n","  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n","\n","  disp.plot(cmap=plt.cm.Blues)\n","  plt.show()\n","\n","  f1_scores = f1_score(y_test, y_pred, average=None)\n","  mean_f1 = np.mean(f1_scores)\n","\n","  print(f\"\\nF1 scores: {f1_scores}\")\n","  print(f\"\\nMean F1 : {mean_f1}\")\n","  print(f\"\\nAccuracy : {accuracy_score(y_test, y_pred)}\")"],"metadata":{"id":"hGOjGnr0wbLw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_a = tf.keras.models.load_model('Model_name16692154860.8846')"],"metadata":{"id":"8gHiJoT1wjJA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  batch_size = 64\n","  train_dataset = tfk.utils.image_dataset_from_directory(\n","      directory=train_folder,\n","      labels=\"inferred\",\n","      label_mode=\"categorical\",\n","      color_mode='rgb',\n","      image_size=(96,96),\n","      batch_size=batch_size\n","  )\n","  validation_dataset = tfk.utils.image_dataset_from_directory(\n","      directory=test_folder,\n","      labels=\"inferred\",\n","      label_mode=\"categorical\",\n","      color_mode='rgb',\n","      image_size=(96,96),\n","  )\n","  AUTOTUNE = tf.data.AUTOTUNE\n","  train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n","  validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jj1S6U00w2Bd","executionInfo":{"status":"ok","timestamp":1669211585113,"user_tz":-60,"elapsed":1653,"user":{"displayName":"Gianmario C","userId":"01154362426832162044"}},"outputId":"217c0c5b-43b7-477e-aa52-0c7b37b51cec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3624 files belonging to 8 classes.\n","Found 719 files belonging to 8 classes.\n"]}]},{"cell_type":"code","source":["show_confusion(model_a, validation_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"l2_zbMSOwq2d","executionInfo":{"status":"ok","timestamp":1669215687545,"user_tz":-60,"elapsed":2933,"user":{"displayName":"Gianmario C","userId":"01154362426832162044"}},"outputId":"30ef2784-c57a-4572-a98f-2ee351889875"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["23/23 [==============================] - 1s 43ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["\n","F1 scores: [0.62295082 0.88607595 0.94273128 0.86238532 0.92372881 0.90666667\n"," 0.95857988 0.82790698]\n","\n","Mean F1 : 0.8663782132875195\n","\n","Accuracy : 0.8873435326842837\n"]}]}]}